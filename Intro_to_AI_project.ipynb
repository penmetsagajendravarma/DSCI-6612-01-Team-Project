{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Phase A"
      ],
      "metadata": {
        "id": "U0I8KOzNyrOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Iwsgdp5wy0PN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3vs02U6vwAH",
        "outputId": "2fe7e102-3d89-4de9-c5b6-088bdc0e12a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pygame opencv-python tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sourabhv/FlapPyBird.git\n",
        "%cd FlapPyBird"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ruCG-sLy596",
        "outputId": "15c56198-158b-4d2e-bd24-909123be6f0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FlapPyBird'...\n",
            "remote: Enumerating objects: 484, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 484 (delta 48), reused 44 (delta 44), pack-reused 412 (from 2)\u001b[K\n",
            "Receiving objects: 100% (484/484), 907.50 KiB | 7.32 MiB/s, done.\n",
            "Resolving deltas: 100% (240/240), done.\n",
            "/content/FlapPyBird\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- collector.py  (overwrite the old file) --------------------\n",
        "import os, csv, random, cv2, numpy as np\n",
        "import pygame\n",
        "from pygame.locals import *\n",
        "\n",
        "# ---------------- CONFIG -----------------\n",
        "EPISODES   = 300                # adjust for more/less data\n",
        "SAVE_DIR   = \"data\"\n",
        "STACK_SIZE = 4\n",
        "RES        = (84, 84)           # H × W of saved frames\n",
        "FPS        = 30\n",
        "# -----------------------------------------\n",
        "\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"        # headless SDL\n",
        "pygame.init()\n",
        "SCREEN      = pygame.display.set_mode((288, 512))\n",
        "FPSCLOCK    = pygame.time.Clock()\n",
        "IMAGES = {\n",
        "    \"bg\"  : pygame.image.load(\"assets/sprites/background-day.png\").convert(),\n",
        "    \"base\": pygame.image.load(\"assets/sprites/base.png\").convert_alpha(),\n",
        "    \"bird\": pygame.image.load(\"assets/sprites/yellowbird-midflap.png\").convert_alpha(),\n",
        "    \"pipe\": [pygame.transform.flip(\n",
        "                 pygame.image.load(\"assets/sprites/pipe-green.png\").convert_alpha(),\n",
        "                 False, True),\n",
        "             pygame.image.load(\"assets/sprites/pipe-green.png\").convert_alpha()]\n",
        "}\n",
        "BASEY = int(512 * 0.79)          # ground y-coord\n",
        "\n",
        "# ---------- helpers -------------------------------------------------\n",
        "def new_pipe_pair():\n",
        "    \"\"\"Return TWO dicts (upper & lower) representing one pipe gap.\"\"\"\n",
        "    gap_y = random.randint(100, 300)\n",
        "    x     = 288 + 10\n",
        "    return [{'x': x, 'y': gap_y - IMAGES[\"pipe\"][0].get_height()},\n",
        "            {'x': x, 'y': gap_y + 100}]\n",
        "\n",
        "def game_step(state, action):\n",
        "    \"\"\"Advance game one frame given action (0/1). Return (state,reward,done).\"\"\"\n",
        "    bird_y, vel_y, pipes = state\n",
        "    # flap\n",
        "    if action and bird_y > -2 * IMAGES[\"bird\"].get_height():\n",
        "        vel_y = -9\n",
        "    # gravity\n",
        "    vel_y = min(vel_y + 1, 10)\n",
        "    bird_y += vel_y\n",
        "    # move pipes\n",
        "    for p in pipes:\n",
        "        p['x'] -= 4\n",
        "    # add new pair when rightmost pair is left of threshold\n",
        "    if pipes[-1]['x'] < 288 - 150:\n",
        "        pipes.extend(new_pipe_pair())\n",
        "    # remove leftmost pair once off-screen\n",
        "    if pipes[0]['x'] < -IMAGES[\"pipe\"][0].get_width():\n",
        "        pipes = pipes[2:]\n",
        "\n",
        "    # collision & reward\n",
        "    reward, done = 0., False\n",
        "    if bird_y + IMAGES[\"bird\"].get_height() >= BASEY:\n",
        "        done, reward = True, -1\n",
        "    else:\n",
        "        for up, lo in zip(pipes[::2], pipes[1::2]):        # iterate over pairs\n",
        "            if up['x'] < 60 < up['x'] + IMAGES[\"pipe\"][0].get_width():\n",
        "                if not (up['y'] + IMAGES[\"pipe\"][0].get_height() < bird_y <\n",
        "                        lo['y'] - IMAGES[\"bird\"].get_height()):\n",
        "                    done, reward = True, -1\n",
        "                    break\n",
        "    if not done and pipes[0]['x'] + 4 == 60:   # passed a pipe\n",
        "        reward = 1\n",
        "    return (bird_y, vel_y, pipes), reward, done\n",
        "\n",
        "def render(state):\n",
        "    \"\"\"Return numpy RGB frame.\"\"\"\n",
        "    bird_y, _, pipes = state\n",
        "    SCREEN.blit(IMAGES[\"bg\"], (0, 0))\n",
        "    for up, lo in zip(pipes[::2], pipes[1::2]):\n",
        "        SCREEN.blit(IMAGES[\"pipe\"][0], (up['x'], up['y']))\n",
        "        SCREEN.blit(IMAGES[\"pipe\"][1], (lo['x'], lo['y']))\n",
        "    SCREEN.blit(IMAGES[\"base\"], (0, BASEY))\n",
        "    SCREEN.blit(IMAGES[\"bird\"], (60, bird_y))\n",
        "    return pygame.surfarray.array3d(SCREEN).swapaxes(0, 1)  # H,W,C\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "csv_path = os.path.join(SAVE_DIR, \"labels.csv\")\n",
        "with open(csv_path, \"w\", newline=\"\") as f_csv:\n",
        "    writer = csv.writer(f_csv)\n",
        "    writer.writerow([\"episode\", \"step\", \"action\", \"reward\", \"done\"])\n",
        "\n",
        "frame_stack = [np.zeros(RES, np.uint8)] * STACK_SIZE\n",
        "counter = 0\n",
        "\n",
        "for ep in range(EPISODES):\n",
        "    state = (int((512 - IMAGES[\"bird\"].get_height()) / 2), -9, list(new_pipe_pair()))\n",
        "    done, step = False, 0\n",
        "    while not done:\n",
        "        action = random.randint(0, 1)  # 0 = no flap, 1 = flap\n",
        "        state, reward, done = game_step(state, action)\n",
        "        frame_rgb = render(state)\n",
        "        frame_gray = cv2.cvtColor(cv2.resize(frame_rgb, RES), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        frame_stack.pop(0)\n",
        "        frame_stack.append(frame_gray)\n",
        "        stacked = np.stack(frame_stack, axis=0)  # shape: (4,84,84)\n",
        "\n",
        "        np.savez_compressed(f\"{SAVE_DIR}/f{counter:07d}\", obs=stacked)\n",
        "        writer = csv.writer(open(csv_path, \"a\", newline=\"\"))\n",
        "        writer.writerow([ep, step, action, reward, int(done)])\n",
        "\n",
        "        counter += 1\n",
        "        step += 1\n",
        "        FPSCLOCK.tick(FPS)\n",
        "\n",
        "print(f\"✅  Saved {counter} stacked frames + CSV in '{SAVE_DIR}/'\")\n",
        "# --------------------------------------------------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t2tW9tHy8oz",
        "outputId": "5b19ed3e-db71-41b8-eae9-13dc1b8ba0e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.11.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "✅  Saved 18000 stacked frames + CSV in 'data/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python collector.py\n",
        "!du -sh data\n",
        "!head data/labels.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJowafuFzGFl",
        "outputId": "5738f8e9-3bb9-48bd-eaf6-79776a986ec7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/FlapPyBird/collector.py': [Errno 2] No such file or directory\n",
            "72M\tdata\n",
            "episode,step,action,reward,done\n",
            "0,0,1,0.0,0\n",
            "0,1,0,0.0,0\n",
            "0,2,0,0.0,0\n",
            "0,3,1,0.0,0\n",
            "0,4,0,0.0,0\n",
            "0,6,1,0.0,0\n",
            "0,7,0,0.0,0\n",
            "0,8,0,0.0,0\n",
            "0,9,0,0.0,0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase B"
      ],
      "metadata": {
        "id": "kQU1r_cS35u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, numpy as np, pandas as pd, torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "DATA_DIR   = \"data\"\n",
        "CSV_PATH   = f\"{DATA_DIR}/labels.csv\"\n",
        "STACK_SIZE = 4            # must match collector\n",
        "RES        = (84, 84)\n",
        "\n",
        "class FlappyFrameStack(Dataset):\n",
        "    def __init__(self, csv_path, root_dir, transform=None):\n",
        "        self.meta = pd.read_csv(csv_path)\n",
        "        self.root = root_dir\n",
        "        self.transform = transform or (lambda x: x)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row  = self.meta.iloc[idx]\n",
        "        path = f\"{self.root}/f{idx:07d}.npz\"      # relies on sequential naming\n",
        "        stack = np.load(path)[\"obs\"] / 255.0      # to float32 [0,1]\n",
        "        stack = torch.from_numpy(stack).float()   # shape (4,84,84)\n",
        "        action = torch.tensor(row.action, dtype=torch.long)\n",
        "        return self.transform(stack), action\n",
        "\n",
        "# transforms (optional – add random crop, noise, etc.)\n",
        "dataset = FlappyFrameStack(CSV_PATH, DATA_DIR)\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "print(\"Batches:\", len(train_loader), \"   Sample shape:\", next(iter(train_loader))[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWvlNFFezLcJ",
        "outputId": "7bf8f663-818a-468a-9e0a-309a6a42a36e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches: 141    Sample shape: torch.Size([128, 4, 84, 84])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Phase B : Supervised CNN Warm-Start -----------------------\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "# 1)  Dataset ----------------------------------------------------------------\n",
        "DATA_DIR = Path(\"data\")          # or your Drive path\n",
        "CSV_PATH = DATA_DIR / \"labels.csv\"\n",
        "\n",
        "class FlappyFrames(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_path, data_dir):\n",
        "        self.meta = pd.read_csv(csv_path)\n",
        "        self.data_dir = data_dir\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "    def __getitem__(self, idx):\n",
        "        row  = self.meta.iloc[idx]\n",
        "        arr  = np.load(self.data_dir / f\"f{idx:07d}.npz\")[\"obs\"]   # uint8 (4,84,84)\n",
        "        arr  = torch.tensor(arr, dtype=torch.float32) / 255.0      # → float32 [0,1]\n",
        "        label= torch.tensor(row.action, dtype=torch.long)\n",
        "        return arr, label\n",
        "\n",
        "full_ds   = FlappyFrames(CSV_PATH, DATA_DIR)\n",
        "train_len = int(0.9 * len(full_ds))          # guarantee exact sum\n",
        "val_len   = len(full_ds) - train_len\n",
        "train_ds, val_ds = random_split(full_ds, [train_len, val_len])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# 2)  Tiny CNN (Atari-style) --------------------------------------------------\n",
        "class TinyCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(4, 32, 8, stride=4), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, stride=1), nn.ReLU(),\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7, 512), nn.ReLU(),   # 3136 = 64×7×7\n",
        "            nn.Linear(512, 2)                    # 2 actions\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.head(self.features(x))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model  = TinyCNN().to(device)\n",
        "opt    = optim.Adam(model.parameters(), lr=1e-4)\n",
        "loss_fn= nn.CrossEntropyLoss()\n",
        "\n",
        "# 3)  Train 5 epochs ----------------------------------------------------------\n",
        "for epoch in range(5):\n",
        "    model.train(); total_loss = 0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = loss_fn(model(xb), yb); loss.backward(); opt.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    train_loss = total_loss / train_len\n",
        "\n",
        "    model.eval(); correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            preds = model(xb).argmax(1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total   += yb.size(0)\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1} | loss {train_loss:.4f} | val acc {acc:.2f}%\")\n",
        "\n",
        "# 4)  Save weights for RL -----------------------------------------------------\n",
        "torch.save(model.state_dict(), \"cnn_supervised.pth\")\n",
        "print(\"✅  Saved cnn_supervised.pth — ready for RL warm-start\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xmEe8cv3il1",
        "outputId": "d3b1517c-5f28-420d-80bb-5f4f7a6eaaea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | loss 0.6932 | val acc 50.50%\n",
            "Epoch 2 | loss 0.6933 | val acc 50.50%\n",
            "Epoch 3 | loss 0.6932 | val acc 49.72%\n",
            "Epoch 4 | loss 0.6932 | val acc 49.50%\n",
            "Epoch 5 | loss 0.6931 | val acc 49.67%\n",
            "✅  Saved cnn_supervised.pth — ready for RL warm-start\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTbluU478WqG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}